{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdYLQme0j0XHEudR39u+G7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anas1IA/training_Graph_CNN/blob/main/Training__model_CNN_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "import torch\n",
        "from torch.nn import Linear ,BatchNorm1d\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "import os.path as osp\n",
        "import torch\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "uGDmwMA9ptNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y unrar"
      ],
      "metadata": {
        "id": "K_8pd214erjT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/dataset1\n"
      ],
      "metadata": {
        "id": "iIScV0Xihrse"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x dataset.rar /content/datasetA/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lcpYSTwfH12",
        "outputId": "e92fe95f-08e7-43f5-b981-2f72acd432c2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from dataset.rar\n",
            "\n",
            "Creating    /content/datasetA/dataset                                 OK\n",
            "Creating    /content/datasetA/dataset/processed                       OK\n",
            "Extracting  /content/datasetA/dataset/processed/data.pt                  \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/processed/pre_filter.pt            \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/processed/pre_transform.pt         \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Creating    /content/datasetA/dataset/raw                             OK\n",
            "Extracting  /content/datasetA/dataset/raw/A.json                         \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/B.json                         \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/C.json                         \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/D.json                         \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/del.json                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/E.json                         \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/F.json                         \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/G.json                         \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/H.json                         \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/I.json                         \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/J.json                         \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/K.json                         \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/L.json                         \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/M.json                         \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/N.json                         \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/O.json                         \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/P.json                         \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/Q.json                         \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/R.json                         \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/S.json                         \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/space.json                     \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/T.json                         \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/U.json                         \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/V.json                         \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/W.json                         \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/X.json                         \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/Y.json                         \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  /content/datasetA/dataset/raw/Z.json                         \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir('/content/datasetA/'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x39jo4-lfLTj",
        "outputId": "1178d529-5f0d-4b60-8c07-01fbdd007502"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwpwIvE2f-Xc",
        "outputId": "f0f98be5-8ef5-4e03-82d1-767eb8822884"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class ASLDataset(InMemoryDataset):\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return sorted(os.listdir(self.raw_dir))\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def edge_index(self) -> torch.tensor:\n",
        "        return torch.tensor([[0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 5, 5, 5, 6, 6, 7, 7, 8, 9, 9, 9, 10, 10, 11, 11, 12, 13, 13, 13, 14, 14, 15, 15, 16, 17, 17, 17, 18, 18, 19, 19, 20],\n",
        "                             [1, 5, 17, 0, 2, 1, 3, 2, 4, 3, 0, 6, 9, 5, 7, 6, 8, 7, 5, 10, 13, 9, 11, 10, 12, 11, 9, 14, 17, 13, 15, 14, 16, 15, 0, 13, 18, 17, 19, 18, 20, 19]]\n",
        "                            ).type(torch.long)\n",
        "\n",
        "    def download(self):\n",
        "        ...\n",
        "\n",
        "    def process(self):\n",
        "\n",
        "        data_list = []\n",
        "\n",
        "        chars = []\n",
        "\n",
        "        for char in self.raw_file_names:\n",
        "\n",
        "            jsn = json.load(open(osp.join(self.raw_dir, char), \"r\"))\n",
        "\n",
        "            y = torch.tensor(jsn[\"label\"])\n",
        "\n",
        "            if len(samples := jsn[\"samples\"]) != 0:\n",
        "\n",
        "                chars.append(char)\n",
        "\n",
        "                for sample in samples:\n",
        "\n",
        "                    x = torch.tensor(sample[\"x\"]).type(torch.float32)\n",
        "\n",
        "                    data = Data(edge_index=self.edge_index(), x=x, y=y)\n",
        "\n",
        "                    data_list.append(data)\n",
        "\n",
        "\n",
        "            self.data, self.slices = self.collate(data_list)\n",
        "\n",
        "            torch.save((self._data, self.slices), self.processed_paths[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gap6X0sRjOsz",
        "outputId": "aa3e22ab-551e-44e3-d739-fa028d71abea"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASLDataset(6486)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = ASLDataset(root=\"datasetA/dataset\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "rhPBZ8dUpOlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1NpM7ayVPQb",
        "outputId": "bd057a1b-ec25-4ec2-bfb2-e2a5e0774efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.1041\n",
            "Epoch: 002, Train Acc: 0.1101\n",
            "Epoch: 003, Train Acc: 0.1113\n",
            "Epoch: 004, Train Acc: 0.1135\n",
            "Epoch: 005, Train Acc: 0.1213\n",
            "Epoch: 006, Train Acc: 0.1142\n",
            "Epoch: 007, Train Acc: 0.1292\n",
            "Epoch: 008, Train Acc: 0.1343\n",
            "Epoch: 009, Train Acc: 0.1331\n",
            "Epoch: 010, Train Acc: 0.1206\n",
            "Epoch: 011, Train Acc: 0.1363\n",
            "Epoch: 012, Train Acc: 0.1391\n",
            "Epoch: 013, Train Acc: 0.1369\n",
            "Epoch: 014, Train Acc: 0.1304\n",
            "Epoch: 015, Train Acc: 0.1422\n",
            "Epoch: 016, Train Acc: 0.1429\n",
            "Epoch: 017, Train Acc: 0.1378\n",
            "Epoch: 018, Train Acc: 0.1409\n",
            "Epoch: 019, Train Acc: 0.1411\n",
            "Epoch: 020, Train Acc: 0.1438\n",
            "Epoch: 021, Train Acc: 0.1496\n",
            "Epoch: 022, Train Acc: 0.1506\n",
            "Epoch: 023, Train Acc: 0.1548\n",
            "Epoch: 024, Train Acc: 0.1406\n",
            "Epoch: 025, Train Acc: 0.1619\n",
            "Epoch: 026, Train Acc: 0.1355\n",
            "Epoch: 027, Train Acc: 0.1355\n",
            "Epoch: 028, Train Acc: 0.1459\n",
            "Epoch: 029, Train Acc: 0.1594\n",
            "Epoch: 030, Train Acc: 0.1474\n",
            "Epoch: 031, Train Acc: 0.1468\n",
            "Epoch: 032, Train Acc: 0.1496\n",
            "Epoch: 033, Train Acc: 0.1511\n",
            "Epoch: 034, Train Acc: 0.1500\n",
            "Epoch: 035, Train Acc: 0.1577\n",
            "Epoch: 036, Train Acc: 0.1542\n",
            "Epoch: 037, Train Acc: 0.1593\n",
            "Epoch: 038, Train Acc: 0.1443\n",
            "Epoch: 039, Train Acc: 0.1642\n",
            "Epoch: 040, Train Acc: 0.1674\n",
            "Epoch: 041, Train Acc: 0.1528\n",
            "Epoch: 042, Train Acc: 0.1605\n",
            "Epoch: 043, Train Acc: 0.1718\n",
            "Epoch: 044, Train Acc: 0.1437\n",
            "Epoch: 045, Train Acc: 0.1702\n",
            "Epoch: 046, Train Acc: 0.1611\n",
            "Epoch: 047, Train Acc: 0.1659\n",
            "Epoch: 048, Train Acc: 0.1599\n",
            "Epoch: 049, Train Acc: 0.1517\n",
            "Epoch: 050, Train Acc: 0.1519\n",
            "Epoch: 051, Train Acc: 0.1423\n",
            "Epoch: 052, Train Acc: 0.1514\n",
            "Epoch: 053, Train Acc: 0.1627\n",
            "Epoch: 054, Train Acc: 0.1619\n",
            "Epoch: 055, Train Acc: 0.1610\n",
            "Epoch: 056, Train Acc: 0.1565\n",
            "Epoch: 057, Train Acc: 0.1579\n",
            "Epoch: 058, Train Acc: 0.1628\n",
            "Epoch: 059, Train Acc: 0.1738\n",
            "Epoch: 060, Train Acc: 0.1565\n",
            "Epoch: 061, Train Acc: 0.1565\n",
            "Epoch: 062, Train Acc: 0.1551\n",
            "Epoch: 063, Train Acc: 0.1728\n",
            "Epoch: 064, Train Acc: 0.1590\n",
            "Epoch: 065, Train Acc: 0.1386\n",
            "Epoch: 066, Train Acc: 0.1751\n",
            "Epoch: 067, Train Acc: 0.1698\n",
            "Epoch: 068, Train Acc: 0.1600\n",
            "Epoch: 069, Train Acc: 0.1636\n",
            "Epoch: 070, Train Acc: 0.1693\n",
            "Epoch: 071, Train Acc: 0.1799\n",
            "Epoch: 072, Train Acc: 0.1607\n",
            "Epoch: 073, Train Acc: 0.1670\n",
            "Epoch: 074, Train Acc: 0.1625\n",
            "Epoch: 075, Train Acc: 0.1665\n",
            "Epoch: 076, Train Acc: 0.1705\n",
            "Epoch: 077, Train Acc: 0.1816\n",
            "Epoch: 078, Train Acc: 0.1731\n",
            "Epoch: 079, Train Acc: 0.1480\n",
            "Epoch: 080, Train Acc: 0.1684\n",
            "Epoch: 081, Train Acc: 0.1679\n",
            "Epoch: 082, Train Acc: 0.1597\n",
            "Epoch: 083, Train Acc: 0.1664\n",
            "Epoch: 084, Train Acc: 0.1571\n",
            "Epoch: 085, Train Acc: 0.1725\n",
            "Epoch: 086, Train Acc: 0.1684\n",
            "Epoch: 087, Train Acc: 0.1716\n",
            "Epoch: 088, Train Acc: 0.1812\n",
            "Epoch: 089, Train Acc: 0.1705\n",
            "Epoch: 090, Train Acc: 0.1750\n",
            "Epoch: 091, Train Acc: 0.1708\n",
            "Epoch: 092, Train Acc: 0.1721\n",
            "Epoch: 093, Train Acc: 0.1830\n",
            "Epoch: 094, Train Acc: 0.1770\n",
            "Epoch: 095, Train Acc: 0.1779\n",
            "Epoch: 096, Train Acc: 0.1773\n",
            "Epoch: 097, Train Acc: 0.1889\n",
            "Epoch: 098, Train Acc: 0.1741\n",
            "Epoch: 099, Train Acc: 0.1742\n",
            "Epoch: 100, Train Acc: 0.1904\n",
            "Epoch: 101, Train Acc: 0.1872\n",
            "Epoch: 102, Train Acc: 0.1815\n",
            "Epoch: 103, Train Acc: 0.1832\n",
            "Epoch: 104, Train Acc: 0.1855\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print(len(dataset))\n",
        "torch.manual_seed(12345)\n",
        "dataset = dataset\n",
        "\n",
        "train_dataset = dataset\n",
        "# test_dataset = dataset[600:]\n",
        "\n",
        "# print(f'Number of training graphs: {len(train_dataset)}')\n",
        "# print(f'Number of test graphs: {len(test_dataset)}')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# for step, data in enumerate(train_loader):\n",
        "#     print(f'Step {step + 1}:')\n",
        "#     print('=======')\n",
        "#     print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "#     print(data)\n",
        "#     print()\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "        # self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        # x = x.relu()\n",
        "        # x = self.conv3(x, edge_index)\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        # x = F.dropout(x, p=0.4, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "# model = GCN(hidden_channels=64)\n",
        "# print(model)\n",
        "model = GCN(hidden_channels=128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "         loss = criterion(out, data.y)  # Compute the loss.\n",
        "         loss.backward()  # Derive gradients.\n",
        "         optimizer.step()  # Update parameters based on gradients.\n",
        "         optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)\n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "for epoch in range(1, 400):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    # test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-BEPVLgp1z5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}